{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce053d77-e779-410c-b7ee-0abf0d457344",
   "metadata": {},
   "source": [
    "# Assemble\n",
    "\n",
    "This notebook loads and assembles all your basic data sources, including tabulor and geospatial data.\n",
    "\n",
    "The final output is two dataframes:\n",
    "\n",
    "- UNIVERSE\n",
    "- SALES\n",
    "\n",
    "The SALES dataframe represents transactions or parcels; these are ownership transfers with prices, dates, and metadata.  \n",
    "The UNIVERSE dataframe represents the parcels themselves (land and buildings, and their associated characteristics).\n",
    "\n",
    "These will be packaged together in a handy data structure called a `SalesUniversePair`, or `sup` for short. `openavmkit` provides many handy functions that carefully perform operations on `sup`s without mixing up their fields.\n",
    "\n",
    "The key thing to understand is that the **Assemble** notebook outputs a `sup` that represents *factual assertions* about the world. In later notebooks, we will have to add assumptions, opinions, and educated guesses, but we first will establish the firmest facts we can in this notebook.\n",
    "\n",
    "You can think of the two dataframes in the `sup` as answering the following questions:\n",
    "\n",
    "- UNIVERSE:\n",
    "  - Where is each parcel located in space, and what is its shape?\n",
    "  - What are the *current* characteristics of each parcel?\n",
    "    - Which parcels have buildings and which are vacant lots?\n",
    "    - How big is each parcel?\n",
    "    - What is the age/size/quality/condition/etc of each building?\n",
    "- SALES:\n",
    "  - Which parcels have sold?\n",
    "  - What prices did they sell for?\n",
    "  - What dates did they sell on?\n",
    "  - Which sales were valid?\n",
    "  - What characteristics were different *at the time of sale* from how the parcel is now?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these as desired\n",
    "\n",
    "# The slug of the locality you are currently working on\n",
    "locality = \"us-nc-guilford\"\n",
    "\n",
    "# Whether to print out a lot of stuff (can help with debugging) or stay mostly quiet\n",
    "verbose = True\n",
    "\n",
    "# Clear previous state for this notebook and start fresh\n",
    "clear_checkpoints = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11d468-1d7d-43eb-81ed-a983c5fb78b7",
   "metadata": {},
   "source": [
    "# 1. Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1414e0d-5738-4713-8b1d-e6d66930b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup completed.\n"
     ]
    }
   ],
   "source": [
    "import init_notebooks\n",
    "init_notebooks.setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e670e4a6-4e2e-4d78-95bd-978a2bd12d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OpenAVMkit:\n",
    "from openavmkit.pipeline import ( \n",
    "    init_notebook,\n",
    "    from_checkpoint,\n",
    "    delete_checkpoints,\n",
    "    examine_df,\n",
    "    examine_df_in_ridiculous_detail,\n",
    "    examine_sup,\n",
    "    examine_sup_in_ridiculous_detail,\n",
    "    cloud_sync,\n",
    "    load_settings,\n",
    "    load_dataframes,\n",
    "    process_data,\n",
    "    process_sales,\n",
    "    tag_model_groups_sup,\n",
    "    write_notebook_output_sup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c38b672-1f29-4e9f-b32c-671810b1c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locality = us-nc-guilford\n",
      "base path = C:\\MaxClark\\openavmkit\\notebooks\\pipeline\n",
      "current path = C:\\MaxClark\\openavmkit\\notebooks\\pipeline\\data\\us-nc-guilford\n"
     ]
    }
   ],
   "source": [
    "init_notebook(locality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c05828b-a5bf-420f-8dfc-e1fe86f3afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if clear_checkpoints:\n",
    "    delete_checkpoints(\"1-assemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e77949-e681-4d7c-bbd8-86284d4e883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = load_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2b771-08a9-4512-9fa8-4dd2119c213c",
   "metadata": {},
   "source": [
    "# 2. Sync with Cloud\n",
    "- If you have configured cloud storage, syncs with your remote storage\n",
    "- Reconciles your local input files with the versions on the remote server\n",
    "- Pulls down whatever is newer from the remote server\n",
    "- Uploads whatever is newer from your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f4d61d-52f3-4c1c-9bef-d06a412f091e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing cloud service of type 'huggingface' with access 'read_write'...\n",
      "_init_service('huggingface', 'read_write')\n",
      "ignore_paths = []\n",
      "Syncing files from local=\"in\" to remote=\"us/nc/guilford/\"...\n",
      "RepoFolder(path='us/nc/guilford/geo', tree_id='fc00d683410acadc70a33d0df67f37d24c196de7', last_commit=LastCommitInfo(oid='90979a1b96ec27efc351ca1ac7635bb716f580e9', title='Upload via OpenAVMKit', date=datetime.datetime(2025, 2, 28, 21, 16, 2, tzinfo=datetime.timezone.utc)))\n",
      "us/nc/guilford/settings.json\n",
      "Local file 'in/building.csv' missing for remote file 'us/nc/guilford/building.csv'. Downloading...\n",
      "Downloading 'in/building.csv' <-- 'us/nc/guilford/building.csv'...\n",
      "Local file 'in/caprates.csv' missing for remote file 'us/nc/guilford/caprates.csv'. Downloading...\n",
      "Downloading 'in/caprates.csv' <-- 'us/nc/guilford/caprates.csv'...\n",
      "Local file 'in/elevation.csv' missing for remote file 'us/nc/guilford/elevation.csv'. Downloading...\n",
      "Downloading 'in/elevation.csv' <-- 'us/nc/guilford/elevation.csv'...\n",
      "Local file 'in/geo/airport.parquet' missing for remote file 'us/nc/guilford/geo/airport.parquet'. Downloading...\n",
      "Downloading 'in/geo/airport.parquet' <-- 'us/nc/guilford/geo/airport.parquet'...\n",
      "Local file 'in/geo/census_block_groups.parquet' missing for remote file 'us/nc/guilford/geo/census_block_groups.parquet'. Downloading...\n",
      "Downloading 'in/geo/census_block_groups.parquet' <-- 'us/nc/guilford/geo/census_block_groups.parquet'...\n",
      "Local file 'in/geo/census_tracts.parquet' missing for remote file 'us/nc/guilford/geo/census_tracts.parquet'. Downloading...\n",
      "Downloading 'in/geo/census_tracts.parquet' <-- 'us/nc/guilford/geo/census_tracts.parquet'...\n",
      "Local file 'in/geo/central_business_district.parquet' missing for remote file 'us/nc/guilford/geo/central_business_district.parquet'. Downloading...\n",
      "Downloading 'in/geo/central_business_district.parquet' <-- 'us/nc/guilford/geo/central_business_district.parquet'...\n",
      "Local file 'in/geo/city.parquet' missing for remote file 'us/nc/guilford/geo/city.parquet'. Downloading...\n",
      "Downloading 'in/geo/city.parquet' <-- 'us/nc/guilford/geo/city.parquet'...\n",
      "Local file 'in/geo/colleges.parquet' missing for remote file 'us/nc/guilford/geo/colleges.parquet'. Downloading...\n",
      "Downloading 'in/geo/colleges.parquet' <-- 'us/nc/guilford/geo/colleges.parquet'...\n",
      "Local file 'in/geo/lakes.parquet' missing for remote file 'us/nc/guilford/geo/lakes.parquet'. Downloading...\n",
      "Downloading 'in/geo/lakes.parquet' <-- 'us/nc/guilford/geo/lakes.parquet'...\n",
      "Local file 'in/geo/parcels.parquet' missing for remote file 'us/nc/guilford/geo/parcels.parquet'. Downloading...\n",
      "Downloading 'in/geo/parcels.parquet' <-- 'us/nc/guilford/geo/parcels.parquet'...\n",
      "Local file 'in/geo/parks.parquet' missing for remote file 'us/nc/guilford/geo/parks.parquet'. Downloading...\n",
      "Downloading 'in/geo/parks.parquet' <-- 'us/nc/guilford/geo/parks.parquet'...\n",
      "Local file 'in/geo/school_district.parquet' missing for remote file 'us/nc/guilford/geo/school_district.parquet'. Downloading...\n",
      "Downloading 'in/geo/school_district.parquet' <-- 'us/nc/guilford/geo/school_district.parquet'...\n",
      "Local file 'in/geo/streams.parquet' missing for remote file 'us/nc/guilford/geo/streams.parquet'. Downloading...\n",
      "Downloading 'in/geo/streams.parquet' <-- 'us/nc/guilford/geo/streams.parquet'...\n",
      "Local file 'in/geo/universities.parquet' missing for remote file 'us/nc/guilford/geo/universities.parquet'. Downloading...\n",
      "Downloading 'in/geo/universities.parquet' <-- 'us/nc/guilford/geo/universities.parquet'...\n",
      "Local file 'in/geo/zoning.parquet' missing for remote file 'us/nc/guilford/geo/zoning.parquet'. Downloading...\n",
      "Downloading 'in/geo/zoning.parquet' <-- 'us/nc/guilford/geo/zoning.parquet'...\n",
      "Local file 'in/noise.csv' missing for remote file 'us/nc/guilford/noise.csv'. Downloading...\n",
      "Downloading 'in/noise.csv' <-- 'us/nc/guilford/noise.csv'...\n",
      "Local file 'in/parcels.csv' missing for remote file 'us/nc/guilford/parcels.csv'. Downloading...\n",
      "Downloading 'in/parcels.csv' <-- 'us/nc/guilford/parcels.csv'...\n",
      "Local file 'in/ref_zoning.csv' missing for remote file 'us/nc/guilford/ref_zoning.csv'. Downloading...\n",
      "Downloading 'in/ref_zoning.csv' <-- 'us/nc/guilford/ref_zoning.csv'...\n",
      "Local file 'in/sale.csv' missing for remote file 'us/nc/guilford/sale.csv'. Downloading...\n",
      "Downloading 'in/sale.csv' <-- 'us/nc/guilford/sale.csv'...\n",
      "\n",
      "Conflict for 'us/nc/guilford/settings.json':\n",
      "-->Local  - size:          2 bytes, modified: 2025-04-28 04:25:58.144883+00:00\n",
      "-->Remote - size:     28,931 bytes, modified: 2025-04-12 19:47:20+00:00\n",
      "-->Size delta:     28,929 bytes\n",
      "-->Time delta: 15 days, 8:38:38.144883\n",
      "  Local file is newer. Uploading local version...\n",
      "Uploading 'in/settings.json' --> 'us/nc/guilford/settings.json'...\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "(Request ID: Root=1-680f03ae-35e87923673fd5897a504c08;6fc77f74-f6a8-48e7-ad8d-134347e4ac0e)\n\n403 Forbidden: Forbidden: you must use a write token to upload to a repository..\nCannot access content at: https://huggingface.co/api/datasets/landeconomics/localities-public/preupload/main.\nMake sure your token has the correct permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/datasets/landeconomics/localities-public/preupload/main",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcloud_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../../.env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\openavmkit\\pipeline.py:775\u001b[0m, in \u001b[0;36mcloud_sync\u001b[1;34m(locality, verbose, env_path, settings, dry_run, ignore_paths)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_paths = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mignore_paths\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    774\u001b[0m remote_path \u001b[38;5;241m=\u001b[39m locality\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 775\u001b[0m \u001b[43mcloud_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43min\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_paths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\openavmkit\\cloud\\base.py:227\u001b[0m, in \u001b[0;36mCloudService.sync_files\u001b[1;34m(self, locality, local_folder, remote_folder, dry_run, verbose, ignore_paths)\u001b[0m\n\u001b[0;32m    225\u001b[0m       _print_upload(file\u001b[38;5;241m.\u001b[39mname, local_file_path)\n\u001b[0;32m    226\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dry_run:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Process files that exist locally but not remotely.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m local_files:\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\openavmkit\\cloud\\huggingface.py:89\u001b[0m, in \u001b[0;36mHuggingFaceService.upload_file\u001b[1;34m(self, remote_file_path, local_file_path)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupload_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, remote_file_path: \u001b[38;5;28mstr\u001b[39m, local_file_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     88\u001b[0m   \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupload_file(remote_file_path, local_file_path)\n\u001b[1;32m---> 89\u001b[0m   \u001b[43mhf_upload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_fileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_in_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUpload via OpenAVMKit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     96\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:1551\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_as_future(fn, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[1;32m-> 1551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:4435\u001b[0m, in \u001b[0;36mHfApi.upload_file\u001b[1;34m(self, path_or_fileobj, path_in_repo, repo_id, token, repo_type, revision, commit_message, commit_description, create_pr, parent_commit, run_as_future)\u001b[0m\n\u001b[0;32m   4427\u001b[0m commit_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4428\u001b[0m     commit_message \u001b[38;5;28;01mif\u001b[39;00m commit_message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_in_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with huggingface_hub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4429\u001b[0m )\n\u001b[0;32m   4430\u001b[0m operation \u001b[38;5;241m=\u001b[39m CommitOperationAdd(\n\u001b[0;32m   4431\u001b[0m     path_or_fileobj\u001b[38;5;241m=\u001b[39mpath_or_fileobj,\n\u001b[0;32m   4432\u001b[0m     path_in_repo\u001b[38;5;241m=\u001b[39mpath_in_repo,\n\u001b[0;32m   4433\u001b[0m )\n\u001b[1;32m-> 4435\u001b[0m commit_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_commit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4438\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_commit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_info\u001b[38;5;241m.\u001b[39mpr_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4448\u001b[0m     revision \u001b[38;5;241m=\u001b[39m quote(_parse_revision_from_pr_url(commit_info\u001b[38;5;241m.\u001b[39mpr_url), safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:1551\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_as_future(fn, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[1;32m-> 1551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:3991\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[1;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit, run_as_future)\u001b[0m\n\u001b[0;32m   3988\u001b[0m \u001b[38;5;66;03m# If updating twice the same file or update then delete a file in a single commit\u001b[39;00m\n\u001b[0;32m   3989\u001b[0m _warn_on_overwriting_operations(operations)\n\u001b[1;32m-> 3991\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreupload_lfs_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munquoted_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# first-class methods take unquoted revision\u001b[39;49;00m\n\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfree_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# do not remove `CommitOperationAdd.path_or_fileobj` on LFS files for \"normal\" users\u001b[39;49;00m\n\u001b[0;32m   4000\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4002\u001b[0m files_to_copy \u001b[38;5;241m=\u001b[39m _fetch_files_to_copy(\n\u001b[0;32m   4003\u001b[0m     copies\u001b[38;5;241m=\u001b[39mcopies,\n\u001b[0;32m   4004\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4008\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[0;32m   4009\u001b[0m )\n\u001b[0;32m   4010\u001b[0m \u001b[38;5;66;03m# Remove no-op operations (files that have not changed)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:4214\u001b[0m, in \u001b[0;36mHfApi.preupload_lfs_files\u001b[1;34m(self, repo_id, additions, token, repo_type, revision, create_pr, num_threads, free_memory, gitignore_content)\u001b[0m\n\u001b[0;32m   4212\u001b[0m \u001b[38;5;66;03m# Check which new files are LFS\u001b[39;00m\n\u001b[0;32m   4213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4214\u001b[0m     \u001b[43m_fetch_upload_modes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4215\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_additions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgitignore_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgitignore_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   4225\u001b[0m     e\u001b[38;5;241m.\u001b[39mappend_to_message(_CREATE_COMMIT_NO_REPO_ERROR_MESSAGE)\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\_commit_api.py:542\u001b[0m, in \u001b[0;36m_fetch_upload_modes\u001b[1;34m(additions, repo_type, repo_id, headers, revision, endpoint, create_pr, gitignore_content)\u001b[0m\n\u001b[0;32m    534\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgitIgnore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gitignore_content\n\u001b[0;32m    536\u001b[0m resp \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/preupload/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    538\u001b[0m     json\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[0;32m    539\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    540\u001b[0m     params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_pr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m create_pr \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    541\u001b[0m )\n\u001b[1;32m--> 542\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m preupload_info \u001b[38;5;241m=\u001b[39m _validate_preupload_info(resp\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m    544\u001b[0m upload_modes\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]: file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muploadMode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m preupload_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mC:\\MaxClark\\openavmkit\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:472\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    467\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure your token has the correct permissions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    471\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m416\u001b[39m:\n\u001b[0;32m    475\u001b[0m     range_header \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m: (Request ID: Root=1-680f03ae-35e87923673fd5897a504c08;6fc77f74-f6a8-48e7-ad8d-134347e4ac0e)\n\n403 Forbidden: Forbidden: you must use a write token to upload to a repository..\nCannot access content at: https://huggingface.co/api/datasets/landeconomics/localities-public/preupload/main.\nMake sure your token has the correct permissions."
     ]
    }
   ],
   "source": [
    "cloud_sync(locality, verbose=True, env_path=\"../../../.env\", settings=settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e301d1-0416-4512-8da9-130569a2b1e0",
   "metadata": {},
   "source": [
    "# 3. Load & process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0427dfa-883f-49a5-8344-353264eec4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all of our initial dataframes, but don't do anything with them just yet\n",
    "dataframes = from_checkpoint(\"1-assemble-01-load_dataframes\", load_dataframes,\n",
    "    {\n",
    "        \"settings\":settings,\n",
    "        \"verbose\":verbose\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ce66d-8269-42c7-b60d-29c2363c1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble our data\n",
    "sales_univ_pair = from_checkpoint(\"1-assemble-02-process_data\", process_data,\n",
    "    {\n",
    "        \"dataframes\":dataframes, \n",
    "        \"settings\":settings, \n",
    "        \"verbose\":verbose\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878531b-cbe9-401f-a6c1-ed10b9710599",
   "metadata": {},
   "source": [
    "# 4. Inspect results\n",
    "\n",
    "## 4.1 Examine\n",
    "\n",
    "- Run the next cell and look at the printed out results.\n",
    "- Note the \"Non-zero\" and \"Non-null\" columns in particular and make sure they're what you expect\n",
    "- This view is for a quick glance to get a good idea of what all your data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862e4b7-db7d-4662-8a1c-be900f0a12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = load_settings()\n",
    "examine_sup(sales_univ_pair, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9fd42-90eb-41c0-baa1-e417f3753890",
   "metadata": {},
   "source": [
    "## 4.2 Examine in ridiculous detail\n",
    "\n",
    "- You've looked, now LOOK AGAIN. This cell will run `describe()` for each numeric field and `value_counts()` for each categorical field.\n",
    "- Use this info to decide which variables are useful/useless\n",
    "- Consult this readout when you build your modeling group filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9639c-48bf-4086-a114-78651516527f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examine_sup_in_ridiculous_detail(sales_univ_pair, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35091f-a668-4661-af16-58ef31e1c1f0",
   "metadata": {},
   "source": [
    "## 4.3 Look at it on a map\n",
    "\n",
    "- Go to your `out/look/` folder\n",
    "- There should be parquets there\n",
    "- Drop them into ArcGIS, QGIS, or Felt\n",
    "- Look at your location fields and make sure they make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014e0b6-fe72-4d90-b294-fd141d608de1",
   "metadata": {},
   "source": [
    "# 5. Tag modeling groups\n",
    "- Separates rows into groups like \"single family\", \"townhomes\" and \"commercial\" as specified by the user\n",
    "- These groups will guide all further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9d80b-4d56-4c87-ba14-eac97be442fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = load_settings()\n",
    "sales_univ_pair = from_checkpoint(\"1-assemble-04-tag_modeling_groups\", tag_model_groups_sup,\n",
    "    {\n",
    "        \"sup\": sales_univ_pair, \n",
    "        \"settings\": settings, \n",
    "        \"verbose\": verbose\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25049d-3eee-486b-996e-142f0701eb74",
   "metadata": {},
   "source": [
    "# 6. Write out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ae7c9-b1a3-4694-8d4e-e8e0ebbedd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_notebook_output_sup(sales_univ_pair, \"1-assemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f170f00-38bd-4f8c-a734-28fb0cd9a92f",
   "metadata": {},
   "source": [
    "# 7. Look at it on a map!\n",
    "- Take the files output in the previous step and put them in a map viewer like QGIS, ArcGIS, or Felt\n",
    "- Look at them with your eyeballs\n",
    "- Make sure the data looks correct\n",
    "- If not, go back and fix it!\n",
    "- Don't proceed to the next step until everything looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8da3e2-99d7-484e-af80-9ea8322dff31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
